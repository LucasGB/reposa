{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git_crawler import GitCrawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<git_crawler.GitCrawler at 0x21e54242d60>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GitCrawler(['a'], ['b'], 'a/a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "#from SentiCR.SentiCR import SentiCR\n",
    "from SentiSW.code.classification.classifier import Classifier\n",
    "from SentiSW.code.entity.training_set_generation import get_entity\n",
    "import pickle\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "import pymongo\n",
    "\n",
    "users = []\n",
    "tokens = []\n",
    "user = ''\n",
    "token = ''\n",
    "\n",
    "'''\n",
    "mongo_client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "database = mongo_client[\"reposadb\"]\n",
    "pull_requests_collection = database[\"pull_requests\"]\n",
    "repositories_collection = database[\"repositories\"]\n",
    "'''\n",
    "\n",
    "with open('auth.txt', 'r') as file:\n",
    "    for line in file.readlines():\n",
    "        user, token = line.split(':')\n",
    "        users.append(user.replace('\\n', ''))\n",
    "        tokens.append(token.replace('\\n', ''))\n",
    "\n",
    "repositories = []\n",
    "\n",
    "def init():\n",
    "    print('Initialising')\n",
    "\n",
    "\n",
    "    with open('repositories.txt', 'r') as file:\n",
    "        repositories = file.read().splitlines()\n",
    "\n",
    "    for repository in repositories:\n",
    "        owner, name = repository.split(\"/\")\n",
    "        query = { \"_id\" : \"{}/{}\".format(owner, name) }\n",
    "        documento = list(repositories_collection.find(query))\n",
    "\n",
    "        if(len(documento) == 0):\n",
    "            repositories_collection.insert_one({\n",
    "                                                \"_id\" : \"{}/{}\".format(owner, name),\n",
    "                                                \"owner\": owner,\n",
    "                                                \"name\" : name,\n",
    "                                                'open_pull_requests' : [],\n",
    "                                                'closed_pull_requests' : []\n",
    "                                            })\n",
    "\n",
    "def get_tuples(texts):\n",
    "    #sentiment_analyzer = Classifier(read=False, vector_method='tfidf')\n",
    "    #sentiment_analyzer.save_model()\n",
    "    sentiment_analyzer = Classifier(read=True, vector_method='tfidf')\n",
    "    sentiments = sentiment_analyzer.get_sentiment_polarity_collection(texts)\n",
    "\n",
    "    tuples = []\n",
    "    i = 0\n",
    "    for sentiment in sentiments:\n",
    "        t = {'sentiment': sentiment[0]}\n",
    "        if sentiment != 'Neutral':\n",
    "            entity = get_entity(texts[i])\n",
    "            t['entity'] = entity\n",
    "        else:\n",
    "            t['entity'] = None\n",
    "        tuples.append(t)\n",
    "        i = i + 1\n",
    "    return tuples\n",
    "\n",
    "def get_tuple(text):\n",
    "    #sentiment_analyzer = Classifier(read=False, vector_method='tfidf')\n",
    "    #sentiment_analyzer.save_model()\n",
    "    sentiment_analyzer = Classifier(read=True, vector_method='tfidf')\n",
    "    sentiment = sentiment_analyzer.get_sentiment_polarity(text)[0]\n",
    "    ret = {'sentiment': sentiment}\n",
    "    if sentiment != 'Neutral':\n",
    "        entity = get_entity(text)\n",
    "        ret['entity'] = entity\n",
    "    else:\n",
    "        ret['entity'] = None\n",
    "\n",
    "    return ret\n",
    "\n",
    "def classify(sentences):\n",
    "\n",
    "    saved_SentiCR_model = 'classifier_models/SentiCR_model.sav'\n",
    "    \n",
    "    if(os.path.exists(saved_SentiCR_model)):\n",
    "      sentiment_analyzer = pickle.load(open(saved_SentiCR_model, 'rb'))\n",
    "      print('Loaded SentiCR model')\n",
    "    else:\n",
    "      sentiment_analyzer = SentiCR.SentiCR()\n",
    "      pickle.dump(sentiment_analyzer, open(saved_SentiCR_model, 'wb'))\n",
    "      print('Saved model to file')\n",
    "\n",
    "    for sent in sentences:\n",
    "        score = sentiment_analyzer.get_sentiment_polarity(sent)\n",
    "        print(sent+\"\\n Score: \"+str(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TCC",
   "language": "python",
   "name": "tcc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
